{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q sciunit==0.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sciunit\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import json\n",
    "import matplotlib\n",
    "# To avoid figures being plotted on screen (we wish to save to file directly)\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Observation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_observation(observation_path=None):\n",
    "        \n",
    "    #self.observation_path = observation_path\n",
    "    #self.observation_key = observation_key\n",
    "\n",
    "    load_data=m.load(observation_path)\n",
    "    observation_key = list(load_data.keys())[0]\n",
    "    observation = {observation_key: np.array(load_data[observation_key])}\n",
    "   \n",
    "    return observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation=format_observation(observation_path='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation_key = list(observation.keys())[0]\n",
    "# plt.plot(observation[observation_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Model capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cap_generates_spikeraster(sciunit.Capability):\n",
    "    \"\"\"Indicates that the model has a spike raster as output. \"\"\"\n",
    "    \n",
    "    def model_prediction(self):\n",
    "        ...\n",
    "        raise NotImplementedError()\n",
    "       \n",
    "    def get_spikeraster(self):\n",
    "        \"\"\"This function is called by the test, and then the model_prediction function\"\"\"            \n",
    "        spikeraster = self.spikeraster\n",
    "        return spikeraster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BezaireSoltesz_CA1model(sciunit.Model,cap_generates_spikeraster):\n",
    "    \n",
    "    def __init__(self, model_path = '../modeldbca1', results_dir='results', run_dir=None):\n",
    "        sciunit.Model.__init__(self, name = \"BezaireSoltesz_CA1model\")\n",
    "        \n",
    "        self.results_dir = os.path.join(model_path, results_dir)\n",
    "        self.result_path = os.path.join(model_path, results_dir, run_dir)\n",
    "        \n",
    "        self.result_figs = os.path.join(model_path, results_dir, \"figures\", \"Sasaki_experiment\")\n",
    "        if not os.path.exists(self.result_figs):\n",
    "            os.makedirs(self.result_figs)\n",
    "\n",
    "    def result_stimType_path(self, StimType=None):\n",
    "        self.resultStimType_path =  os.path.join(self.results_dir, StimType)\n",
    "\n",
    "    def read_model_result(self, file_name):\n",
    "        file_path = os.path.join(self.result_path, file_name)\n",
    "        with open(file_path, 'r') as fp:\n",
    "            mod_data = np.genfromtxt(fp)\n",
    "        return mod_data    \n",
    "        \n",
    "    def model_prediction(self):\n",
    "        return self.spikeraster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from math import floor\n",
    "\n",
    "cell_types = [ \"ca3cell\", \"pyramidalcell\", \"cckcell\", \"scacell\", \"axoaxoniccell\", \\\n",
    "              \"bistratifiedcell\", \"ivycell\", \"ngfcell\", \"olmcell\", \"pvbasketcell\" ]\n",
    "num_cellTypes = len(cell_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "Duration=20  # Biological time to be simulated, in ms\n",
    "Scale=110\n",
    "# StimType=\"SpikesTrainSingleSpike\"\n",
    "StimType=\"SpikesTrainVaryingFreqPosition\"\n",
    "# StimType=\"SpikesTrainVaryingFreq\"\n",
    "j=10; i=0;\n",
    "run_dir = os.path.join(StimType, f'Scale_{Scale}_{StimType}_00{j}_{i}_SimDuration_{Duration}')\n",
    "model = BezaireSoltesz_CA1model(run_dir = run_dir)\n",
    "cellType = \"pyramidalcell\"\n",
    "neuron_slice_data = model.read_model_result(f'neuron_{cellType}_slice_ids.dat')\n",
    "SlicesNum = 1 + int(max(neuron_slice_data[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedroernesto/.local/lib/python3.7/site-packages/ipykernel_launcher.py:12: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "plt.close('all')\n",
    "\n",
    "ncols = 5\n",
    "for j in range(1,116):\n",
    "    for i in range(0,1):\n",
    "        run_dir =  os.path.join(StimType, f'Scale_{Scale}_{StimType}_0{j}_{i}_SimDuration_{Duration}')\n",
    "        model = BezaireSoltesz_CA1model(run_dir = run_dir)\n",
    "       \n",
    "        spikeraster_data = model.read_model_result('spikeraster.dat')\n",
    "\n",
    "        fig, ax = plt.subplots(2, ncols+1, figsize=(15,5))        \n",
    "        for type_i, cellType in enumerate(cell_types):\n",
    "            row_fig = floor(type_i/ncols)\n",
    "            if row_fig != 0:\n",
    "                ax[row_fig, 0].set_axis_off()\n",
    "            else:\n",
    "                ax[row_fig, 0].plot(spikeraster_data[:,0], spikeraster_data[:,1], 'o', markersize=1)\n",
    "                ax[row_fig, 0].set(ylabel='Neuron-ID', xlabel ='Time (ms)', xlim = [0,Duration+5])\n",
    "            \n",
    "            neuron_slice_data = model.read_model_result(f'neuron_{cellType}_slice_ids.dat')\n",
    "            min_ID = min(neuron_slice_data[:,0]); max_ID = max(neuron_slice_data[:,0])\n",
    "            min_ID = min_ID - (max_ID - min_ID)/10; max_ID = max_ID + (max_ID - min_ID)/10;\n",
    "            \n",
    "            # Filtering out the cellType neurons from the spikeraster data\n",
    "            neuron_spikes_inds = np.in1d(spikeraster_data[:,1], neuron_slice_data[:,0])\n",
    "            ax[row_fig, 1+type_i%ncols].plot(spikeraster_data[neuron_spikes_inds,0], spikeraster_data[neuron_spikes_inds,1], 'o', markersize=1)\n",
    "            ax[row_fig, 1+type_i%ncols].set(ylabel=f'{cellType}-ID', xlabel ='Time (ms)', ylim = [min_ID, max_ID], xlim = [0.9,3.1])\n",
    "            if cellType is not \"ca3cell\":\n",
    "                ax[row_fig, 1+type_i%ncols].set(xlim = [0,1.10*Duration])\n",
    "\n",
    "        # fig.suptitle(f'Current injection = A synchronous single-spike on {j}.{i} % randomly picked CA3-SCs', fontsize=15)\n",
    "        # fig.suptitle(f'Current injection = Poisson spike-trains with {j}.{i} x spont. rate (~13 +-21 Hz) and 2ms-long, on 5 % randomly picked CA3-SCs', fontsize=15)\n",
    "        fig.suptitle(f'Current injection = Poisson spike-trains with {j}.{i} x spont. rate (~13 +-21 Hz), 2ms-long and exponential decay from stim. point on CA3', fontsize=15)            \n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(top=0.85)\n",
    " \n",
    "        if j < 10:\n",
    "            fig_name = f'Scale_{Scale}_{StimType}_000{j}_{i}_SimDuration_{Duration}_all_rasters.png'\n",
    "        elif (j >=10 and j < 100):\n",
    "            fig_name = f'Scale_{Scale}_{StimType}_00{j}_{i}_SimDuration_{Duration}_all_rasters.png'\n",
    "        else:\n",
    "            fig_name = f'Scale_{Scale}_{StimType}_0{j}_{i}_SimDuration_{Duration}_all_rasters.png'\n",
    "\n",
    "        fig_path = os.path.join(model.result_figs, StimType, f'Scale_{Scale}_SimDuration_{Duration}_all_rasters', fig_name)\n",
    "        fig.savefig(fig_path)\n",
    "        \n",
    "        del run_dir, model, spikeraster_data, neuron_slice_data, neuron_spikes_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedroernesto/.local/lib/python3.7/site-packages/ipykernel_launcher.py:12: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "plt.close('all')\n",
    "\n",
    "ncols=5\n",
    "for j in range(1,116):\n",
    "    for i in range(0,1):\n",
    "        run_dir =  os.path.join(StimType, f'Scale_{Scale}_{StimType}_0{j}_{i}_SimDuration_{Duration}')\n",
    "        model = BezaireSoltesz_CA1model(run_dir = run_dir)\n",
    "       \n",
    "        spikeraster_data = model.read_model_result('spikeraster.dat')\n",
    "\n",
    "        fig, ax = plt.subplots(2, ncols+1, figsize=(15,5))        \n",
    "        for type_i, cellType in enumerate(cell_types):\n",
    "            row_fig = floor(type_i/ncols)\n",
    "            if row_fig != 0:\n",
    "                ax[row_fig, 0].set_axis_off()\n",
    "            else:\n",
    "                ax[row_fig, 0].plot(spikeraster_data[:,0], spikeraster_data[:,1], 'o', markersize=1)\n",
    "                ax[row_fig, 0].set(ylabel='Neuron-ID', xlabel ='Time (ms)', xlim = [0,Duration+5])\n",
    "            \n",
    "            neuron_slice_data = model.read_model_result(f'neuron_{cellType}_slice_ids.dat')\n",
    "\n",
    "            min_ID = min(neuron_slice_data[:,0]); max_ID = max(neuron_slice_data[:,0])\n",
    "            min_ID = min_ID - (max_ID - min_ID)/10; max_ID = max_ID + (max_ID - min_ID)/10;            \n",
    "            \n",
    "            # Filtering out the cellType neurons from the slicing data\n",
    "            neuron_spikes_inds = np.in1d(spikeraster_data[:,1], neuron_slice_data[:,0])\n",
    "            neuron_slices_inds = np.in1d(neuron_slice_data[:,0], spikeraster_data[neuron_spikes_inds,1])\n",
    "            ax[row_fig, 1+type_i%ncols].plot(1+neuron_slice_data[neuron_slices_inds,1], neuron_slice_data[neuron_slices_inds,0], 'o', markersize=1)\n",
    "            ax[row_fig, 1+type_i%ncols].set(ylabel=f'{cellType}-ID', xlabel='Slice', xlim=[0, SlicesNum], ylim = [min_ID, max_ID], xticks =range(1,10))\n",
    "\n",
    "        # fig.suptitle(f'Current injection = A synchronous single-spike on {j}.{i} % randomly picked CA3-SCs', fontsize=15)\n",
    "        # fig.suptitle(f'Current injection = Poisson spike-trains with {j}.{i} x spont. rate (~13 +-21 Hz) and 2ms-long, on 5 % randomly picked CA3-SCs', fontsize=15)\n",
    "        fig.suptitle(f'Current injection = Poisson spike-trains with {j}.{i} x spont. rate (~13 +-21 Hz), 2ms-long and exponential decay from stim. point on CA3', fontsize=15)            \n",
    "\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(top=0.90)\n",
    " \n",
    "        if j < 10:\n",
    "            fig_name = f'Scale_{Scale}_{StimType}_000{j}_{i}_SimDuration_{Duration}_all_slices.png'\n",
    "        elif (j >=10 and j < 100):\n",
    "            fig_name = f'Scale_{Scale}_{StimType}_00{j}_{i}_SimDuration_{Duration}_all_slices.png'\n",
    "        else:\n",
    "            fig_name = f'Scale_{Scale}_{StimType}_0{j}_{i}_SimDuration_{Duration}_all_slices.png'\n",
    " \n",
    "\n",
    "        fig_path = os.path.join(model.result_figs, StimType, f'Scale_{Scale}_SimDuration_{Duration}_all_slices', fig_name)\n",
    "        fig.savefig(fig_path)\n",
    "        \n",
    "        del run_dir, model, spikeraster_data, neuron_slice_data, neuron_spikes_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib agg\n",
    "\n",
    "j=10; i=0;\n",
    "run_dir =  os.path.join(StimType, f'Scale_{Scale}_{StimType}_00{j}_{i}_SimDuration_{Duration}')\n",
    "model = BezaireSoltesz_CA1model(run_dir = run_dir)\n",
    "\n",
    "cellType_UnderStudy = cell_types[1]\n",
    "neuron_slice_data = model.read_model_result(f'neuron_{cellType_UnderStudy}_slice_ids.dat')\n",
    "cells_monitored_IDs = []\n",
    "for slice in range(0,SlicesNum):\n",
    "    cells_slice_inds = np.in1d(neuron_slice_data[:,1], [slice])\n",
    "    cells_slice = neuron_slice_data[cells_slice_inds,0]\n",
    "    cells_monitored_IDs.append(np.random.choice(cells_slice, size=101, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedroernesto/.local/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "cell_types = [\"ca3cell\", cellType_UnderStudy]\n",
    "ncols=5\n",
    "for j in range(1,116):\n",
    "    for i in range(0,1):\n",
    "        run_dir =  os.path.join(StimType, f'Scale_{Scale}_{StimType}_0{j}_{i}_SimDuration_{Duration}')\n",
    "        model = BezaireSoltesz_CA1model(run_dir = run_dir)\n",
    "       \n",
    "        spikeraster_data = model.read_model_result('spikeraster.dat')\n",
    "\n",
    "        fig, ax = plt.subplots(1, ncols+1, figsize=(15,3))        \n",
    "        for type_i, cellType in enumerate(cell_types):\n",
    "            \n",
    "            ax[0].plot(spikeraster_data[:,0], spikeraster_data[:,1], 'o', markersize=1)\n",
    "            ax[0].set(ylabel='Neuron-ID', xlabel ='Time (ms)', xlim = [0,Duration+5])\n",
    "            \n",
    "            neuron_slice_data = model.read_model_result(f'neuron_{cellType}_slice_ids.dat')\n",
    "            min_ID = min(neuron_slice_data[:,0]); max_ID = max(neuron_slice_data[:,0])\n",
    "            min_ID = min_ID - (max_ID - min_ID)/10; max_ID = max_ID + (max_ID - min_ID)/10;            \n",
    " \n",
    "            if cellType is not cellType_UnderStudy:\n",
    "                cells_IDs = neuron_slice_data[:,0]\n",
    "            else:\n",
    "                cells_IDs = cells_monitored_IDs\n",
    "\n",
    "            # Filtering out the cellType neurons from the spikeraster data\n",
    "            neuron_spikes_inds = np.in1d(spikeraster_data[:,1], cells_IDs)\n",
    "            ax[1+2*(type_i%2)].plot(spikeraster_data[neuron_spikes_inds,0], spikeraster_data[neuron_spikes_inds,1], 'o', markersize=1)\n",
    "            ax[1+2*(type_i%2)].set(ylabel=f'{cellType}-ID', xlabel ='Time (ms)', xlim = [0.9,3.1], ylim = [min_ID, max_ID] )\n",
    "            if cellType is not \"ca3cell\":\n",
    "                ax[1+2*(type_i%2)].set(xlim = [0,1.10*Duration])\n",
    "                \n",
    "            # Filtering out the cellType neurons from the slicing data \n",
    "            neuron_slices_inds = np.in1d(neuron_slice_data[:,0], spikeraster_data[neuron_spikes_inds,1])\n",
    "            ax[2+2*(type_i%2)].plot(1+neuron_slice_data[neuron_slices_inds,1], neuron_slice_data[neuron_slices_inds,0], 'o', markersize=1)\n",
    "            ax[2+2*(type_i%2)].set(ylabel=f'{cellType}-ID', xlabel='Slice', xlim=[0, SlicesNum], ylim = [min_ID, max_ID], xticks =range(1,10))\n",
    "            \n",
    "            if cellType is cellType_UnderStudy:\n",
    "                slices_act, cells_act = np.unique(neuron_slice_data[neuron_slices_inds,1], return_counts=True)  \n",
    "                all_slices = np.arange(0, 1 + int(max(neuron_slice_data[:,1]) ))    \n",
    "                cell_counts = np.zeros(len(all_slices))\n",
    "                cell_counts[slices_act.astype(int)] = cells_act\n",
    "                ax[3+2*(type_i%2)].plot(1+all_slices, cell_counts, '-o', markersize=5)\n",
    "                ax[3+2*(type_i%2)].set(ylabel=f'{cellType} counts', xlabel='Slice', xlim=[0, SlicesNum],  xticks =range(1,10), ylim=[-5, 110])\n",
    "\n",
    "        # fig.suptitle(f'Current injection = A synchronous single-spike on {j}.{i} % randomly picked CA3-SCs', fontsize=15)\n",
    "        # fig.suptitle(f'Current injection = Poisson spike-trains with {j}.{i} x spont. rate (~13 +-21 Hz) and 2ms-long, on 5 % randomly picked CA3-SCs', fontsize=15)    \n",
    "        fig.suptitle(f'Current injection = Poisson spike-trains with {j}.{i} x spont. rate (~13 +-21 Hz), 2ms-long and exponential decay from stim. point on CA3', fontsize=15)            \n",
    "\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(top=0.82)\n",
    "\n",
    "        if j < 10:\n",
    "            fig_name = f'Scale_{Scale}_{StimType}_000{j}_{i}_SimDuration_{Duration}_all_{cellType_UnderStudy}.png'\n",
    "        elif (j >=10 and j < 100):\n",
    "            fig_name = f'Scale_{Scale}_{StimType}_00{j}_{i}_SimDuration_{Duration}_all_{cellType_UnderStudy}.png'\n",
    "        else:\n",
    "            fig_name = f'Scale_{Scale}_{StimType}_0{j}_{i}_SimDuration_{Duration}_all_{cellType_UnderStudy}.png'\n",
    "            \n",
    "        fig_path = os.path.join(model.result_figs, StimType, f'Scale_{Scale}_SimDuration_{Duration}_all_{cellType_UnderStudy}', fig_name)\n",
    "        fig.savefig(fig_path)\n",
    "        del run_dir, model, spikeraster_data, neuron_slice_data, neuron_spikes_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "\n",
    "cell_types = [ cellType_UnderStudy ]\n",
    "cell_act_mean = []; current_amp = [];\n",
    "\n",
    "model.result_stimType_path(StimType=StimType)\n",
    "results_dirs = os.listdir(model.resultStimType_path)\n",
    "\n",
    "for results_dir in results_dirs:\n",
    "    run_dir = os.path.join(StimType, results_dir)\n",
    "    str = os.path.split(results_dir)[-1]\n",
    "\n",
    "    model = BezaireSoltesz_CA1model(run_dir = run_dir)\n",
    "    spikeraster_data = model.read_model_result('spikeraster.dat')\n",
    "\n",
    "    for type_i, cellType in enumerate(cell_types):\n",
    "        neuron_slice_data = model.read_model_result(f'neuron_{cellType}_slice_ids.dat')\n",
    "\n",
    "        cells_IDs = cells_monitored_IDs\n",
    "\n",
    "        # Filtering out the cellType neurons from the spikeraster data\n",
    "        neuron_spikes_inds = np.in1d(spikeraster_data[:,1], cells_IDs)\n",
    "\n",
    "        # Filtering out the cellType neurons from the slicing data \n",
    "        neuron_slices_inds = np.in1d(neuron_slice_data[:,0], spikeraster_data[neuron_spikes_inds,1])\n",
    "\n",
    "        slices_act, cells_act = np.unique(neuron_slice_data[neuron_slices_inds,1], return_counts=True)  \n",
    "        all_slices = np.arange(0, SlicesNum)   \n",
    "        cell_counts = np.zeros(len(all_slices))\n",
    "        cell_counts[slices_act.astype(int)] = cells_act\n",
    "\n",
    "        cell_act_mean.append(cell_counts.mean())\n",
    "\n",
    "        j = int(str.split('_')[-4]); i = int(str.split('_')[-3])\n",
    "        # current_amp.append(j+i/10) # For StimType = SpikesTrainSingleSpike\n",
    "        current_amp.append((j+i/10)*13) # For StimType = SpikesTrainVaryingFreq or SpikesTrainVaryingFreqPosition\n",
    "        \n",
    "        del neuron_slice_data, cells_IDs, neuron_spikes_inds, neuron_slices_inds\n",
    "\n",
    "    del run_dir, model, spikeraster_data\n",
    "\n",
    "      \n",
    "fig = plt.plot(current_amp, cell_act_mean, 'o', markersize=3)\n",
    "# plt.xlabel('CA3-SCs Current injection effect [%]'); plt.ylabel(f'CA1 {cellType} counts/Slice')\n",
    "plt.xlabel('CA3-SCs Current injection effect [Hz]'); plt.ylabel(f'CA1 {cellType} counts/Slice')\n",
    "plt.title('Input-Output relationship of CA3-CA1 projections', fontsize=15)\n",
    "\n",
    "run_dir =  os.path.join(StimType, f'Scale_{Scale}_{StimType}_0{j}_{i}_SimDuration_{Duration}')\n",
    "model = BezaireSoltesz_CA1model(run_dir = run_dir)\n",
    "\n",
    "fig_name = f'Scale_{Scale}_{StimType}_SimDuration_{Duration}_IO_{cellType_UnderStudy}.png'\n",
    "fig_path = os.path.join(model.result_figs, StimType, fig_name)\n",
    "\n",
    "fig_path = os.path.join(model.result_figs,  StimType, fig_name)\n",
    "plt.savefig(fig_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sciunit.utils as utils\n",
    "import quantities as pq\n",
    "\n",
    "from scipy.stats import power_divergence\n",
    "from collections import namedtuple\n",
    "\n",
    "NeymanResult = namedtuple('NeymanResult', ('statistic_n', 'pvalue'))\n",
    "class NeymanScore(sciunit.Score):\n",
    "    \"\"\"\n",
    "    A Neyman score. A float giving the result of\n",
    "    a Neyman goodness-of-fit test\n",
    "    \"\"\"\n",
    "\n",
    "    _allowed_types = (float,tuple,)\n",
    "\n",
    "    _description = ('A Neyman score. A float giving the result'\n",
    "                    'of a Neyman goodness-of-fit test')\n",
    "\n",
    "    @classmethod\n",
    "    def compute(cls, observation, prediction):\n",
    "        \"\"\"\n",
    "        Computes a Neyman score from an observation and a prediction.\n",
    "        \"\"\"\n",
    "\n",
    "        obs_values = observation[~np.isnan(observation)]\n",
    "        pred_values = prediction[~np.isnan(prediction)]\n",
    "\n",
    "        '''\n",
    "        assert(all(x<=1.00 for x in obs_values) and all(x<=1.00 for x in pred_values)), \\\n",
    "            \"Probabiltity values should not be larger than 1.0\"\n",
    "        obs_values *= 100\n",
    "        pred_values *= 100\n",
    "        '''\n",
    "        \n",
    "        if type(obs_values) is pq.quantity.Quantity:\n",
    "            obs_values = obs_values.magnitude\n",
    "        if type(pred_values) is pq.quantity.Quantity:\n",
    "            pred_values = pred_values.magnitude\n",
    "\n",
    "        Neyman_Result = power_divergence(f_obs=pred_values, f_exp=obs_values, lambda_='neyman')\n",
    "\n",
    "        utils.assert_dimensionless(Neyman_Result.statistic)\n",
    "        utils.assert_dimensionless(Neyman_Result.pvalue)\n",
    "\n",
    "        # Obtaining a score value normalized respect to the mean and std of the Chi-squared distribution\n",
    "        dof = len(obs_values)-1  # degrees of freedom for the Chi-squared distribution\n",
    "        stat = Neyman_Result.statistic\n",
    "        chisq_mean = dof\n",
    "        chisq_std = np.sqrt(2*dof)\n",
    "        stat_n = abs(stat-chisq_mean)/chisq_std\n",
    "        Neyman_result = NeymanResult(stat_n, Neyman_Result.pvalue)\n",
    "\n",
    "        return NeymanScore(Neyman_result)\n",
    "\n",
    "    @property\n",
    "    def sort_key(self):\n",
    "        return self.score\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Neyman-score = %.5f' % self.score.statistic_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sciunit.scores as sci_scores\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sasaki_experiment_test(sciunit.Test):\n",
    "    \n",
    "    score_type = sciunit.Score\n",
    "    \n",
    "    def __init__(self, observation=None, name=\"Sasaki_experiment_test\", base_directory=None):\n",
    "\n",
    "        self.description = \"tests model features related with Sasaki experiment\"\n",
    "        require_capabilities = cap_generates_spikeraster\n",
    "\n",
    "        if not base_directory:\n",
    "            base_directory = \".\"\n",
    "        self.path_test_output = base_directory\n",
    "        # create output directory\n",
    "        if not os.path.exists(self.path_test_output):\n",
    "            os.makedirs(self.path_test_output)\n",
    "\n",
    "        self.figures = []\n",
    "        sciunit.Test.__init__(self, observation, name)\n",
    "        self.observation = observation\n",
    "           \n",
    "    def generate_prediction(self, model, verbose=False):\n",
    "        \"\"\"Implementation of sciunit.Test.generate_prediction\"\"\"\n",
    "\n",
    "        model_dict = model.model_prediction()    \n",
    "        model_key = list(model_dict.keys())[0]\n",
    "        prediction_val = np.array(model_dict[model_key])\n",
    "\n",
    "        observation_key = list(self.observation.keys())[0]\n",
    "        prediction_val = prediction_val[0:len(self.observation[observation_key])] #corrects length, take out later\n",
    "        prediction_dict = {model_key: prediction_val}\n",
    "        \n",
    "        return prediction_dict\n",
    "      \n",
    "    def compute_score(self, observation, prediction, verbose=True):\n",
    "        \"\"\"Implementation of sciunit.Test.score_prediction\"\"\"\n",
    "\n",
    "        #Computing the scores - kept for more keys in observation\n",
    "        #cell_t = list(observation.keys())[0]  # Cell type\n",
    "        #score_cell_dict = dict.fromkeys([key0 for key0 in prediction.keys()], [])\n",
    "        #obs_features = copy.deepcopy(list(observation.values()))[0]\n",
    "        #score_feat_dict = dict()\n",
    "\n",
    "        # compare prediction against observation\n",
    "        prediction_key = list(prediction.keys())[0]\n",
    "        observation_key = list(observation.keys())[0]\n",
    "        score = sum(map(abs,observation[observation_key] - prediction[prediction_key]))/len(observation[observation_key])\n",
    "        self.score = round(score[0], 10)\n",
    "        \n",
    "        # ---------------------- Saving relevant results ----------------------\n",
    "        # Saving figures\n",
    "        fig_prediction = plt.plot(prediction[prediction_key])\n",
    "        fig_observation = plt.plot(observation[observation_key])\n",
    "        self.figures.extend([fig_prediction,fig_observation])\n",
    "\n",
    "        '''\n",
    "        # Saving json file with scores\n",
    "        json_scores_file = mph_plots.jsonFile_MorphStats(testObj=self, dictData=self.score_feat_dict,\n",
    "                                                         prefix_name=\"scores_summary_\")\n",
    "        json_scores_files = json_scores_file.create()\n",
    "        self.figures.extend(json_scores_files)\n",
    "\n",
    "        # Saving table with results\n",
    "        txt_table = mph_plots.TxtTable_MorphStats(testObj=self)\n",
    "        table_files = txt_table.create()\n",
    "        self.figures.extend(table_files)\n",
    "\n",
    "        # Saving figure with scores bar-plot\n",
    "        barplot_figure = mph_plots.ScoresBars_MorphStats(testObj=self)\n",
    "        barplot_files = barplot_figure.create()\n",
    "        self.figures.extend(barplot_files)\n",
    "        '''\n",
    "\n",
    "        return sciunit.Score(self.score)\n",
    "    \n",
    "    def bind_score(self, score, model, observation, prediction):\n",
    "        score.related_data[\"figures\"] = self.figures\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=Sasaki_experiment_test(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.judge(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CircuitModels",
   "language": "python",
   "name": "circuitmodels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
